{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pig6gzYpzi2m"
   },
   "source": [
    "# __TH∆Ø VI·ªÜN__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYvrjXXdzi2p",
    "outputId": "d700e196-6b89-48cf-9b6d-b361456fde2e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import io\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import ast\n",
    "\n",
    "# from vietocr.tool.predictor import Predictor\n",
    "# from vietocr.tool.config import Cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZGJPGjlzi2r"
   },
   "source": [
    "# __D·ªÆ LI·ªÜU__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ILMauMQOzi2r"
   },
   "outputs": [],
   "source": [
    "folder = 'E:\\\\UIT DATA SCIENCE\\\\data samples\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a5n8wf7zi2s",
    "outputId": "ae791693-ec84-458b-9f0c-b9a47d71ed12"
   },
   "outputs": [],
   "source": [
    "file_name = folder + 'vimmsd-private-test.json'\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_private = pd.DataFrame(data)\n",
    "df_private = df_private.transpose()\n",
    "df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEQRtkf9zi2s",
    "outputId": "cc50eb56-36e8-4fde-db2b-7f0d4541e916"
   },
   "outputs": [],
   "source": [
    "file_name = folder + 'vimmsd-public-test.json'\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "df_public = pd.DataFrame(data)\n",
    "df_public = df_public.transpose()\n",
    "df_public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "pqbs8JaRzi2s",
    "outputId": "3edd6b0c-e19b-4f3e-e8f2-0ca85d524aa5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALZ Ch·ªën Sukinchana b√†n th·ªù ƒë·ªôt nhi√™n b·ªã ƒë·ªï r...</td>\n",
       "      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHARK VI·ªÜT: ?NHI·ªÄU NG∆Ø·ªúI ·ªû VI·ªÜT NAM ƒêI L√ÄM CH·ªà...</td>\n",
       "      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>L·ªòN ƒê·∫¶U R·ªíI</td>\n",
       "      <td>46ce5ad52085691fc81869c82e8222c0d737b34fedc2bd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>f816f7152cca9c5899f818ce681cf0949c6964ea2fc5ae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>ƒê∆Ø·ª¢C BI·∫æT, CHI·∫æC M√ÅY C√ÅC NH√Ä KH·∫¢O ·∫¢NH N√ÄY ƒê√É C...</td>\n",
       "      <td>0accae8d37f9edc90b5f0a2f5f3cca773f5d01b5124302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>T·ªö S·∫º D√ôNG C√ÇY V·ªöI M·ªòT B√öA N√ÄY ƒê·∫¨P N√ÅT TAY TH√î...</td>\n",
       "      <td>bf125e295f85c0946940b789b2ba10106b2a85b9e70d88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>Interpool Nh·ªØng k√™ khi ƒë·∫°t m√¥ng m∆° 200ksub Nic...</td>\n",
       "      <td>a8bd707f12b5f47bbb42b501eb1ae896c22a474155ec0d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10805 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Label  \\\n",
       "0                                                    NaN   \n",
       "1      CALZ Ch·ªën Sukinchana b√†n th·ªù ƒë·ªôt nhi√™n b·ªã ƒë·ªï r...   \n",
       "2                                                    NaN   \n",
       "3      SHARK VI·ªÜT: ?NHI·ªÄU NG∆Ø·ªúI ·ªû VI·ªÜT NAM ƒêI L√ÄM CH·ªà...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "10800                                        L·ªòN ƒê·∫¶U R·ªíI   \n",
       "10801                                                NaN   \n",
       "10802  ƒê∆Ø·ª¢C BI·∫æT, CHI·∫æC M√ÅY C√ÅC NH√Ä KH·∫¢O ·∫¢NH N√ÄY ƒê√É C...   \n",
       "10803  T·ªö S·∫º D√ôNG C√ÇY V·ªöI M·ªòT B√öA N√ÄY ƒê·∫¨P N√ÅT TAY TH√î...   \n",
       "10804  Interpool Nh·ªØng k√™ khi ƒë·∫°t m√¥ng m∆° 200ksub Nic...   \n",
       "\n",
       "                                                   image  \n",
       "0      8ae451edcd8ebf697f8763ece249115813149c55733bf8...  \n",
       "1      35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...  \n",
       "2      316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...  \n",
       "3      8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...  \n",
       "4      e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...  \n",
       "...                                                  ...  \n",
       "10800  46ce5ad52085691fc81869c82e8222c0d737b34fedc2bd...  \n",
       "10801  f816f7152cca9c5899f818ce681cf0949c6964ea2fc5ae...  \n",
       "10802  0accae8d37f9edc90b5f0a2f5f3cca773f5d01b5124302...  \n",
       "10803  bf125e295f85c0946940b789b2ba10106b2a85b9e70d88...  \n",
       "10804  a8bd707f12b5f47bbb42b501eb1ae896c22a474155ec0d...  \n",
       "\n",
       "[10805 rows x 2 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images = pd.read_excel(folder + 'file_train.xlsx')\n",
    "df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>label</th>\n",
       "      <th>image_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8ae451edcd8ebf697f8763ece249115813149c55733bf8...</td>\n",
       "      <td>C√¥ ·∫•y tr√™n m·∫°ng vs c√¥ ·∫•y ngo√†i ƒë·ªùi =)))</td>\n",
       "      <td>multi-sarcasm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...</td>\n",
       "      <td>Ng∆∞·ªùi t√¢m linh giao ti·∫øp v·ªõi ng∆∞·ªùi th·ª±c t·∫ø :)))</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>CALZ Ch·ªën Sukinchana b√†n th·ªù ƒë·ªôt nhi√™n b·ªã ƒë·ªï r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...</td>\n",
       "      <td>H√¨nh nh∆∞ TrƒÉng h√¥m nay ƒë·∫πp qu√° m·ªçi ng∆∞·ªùi ·∫°! üòÉ ...</td>\n",
       "      <td>multi-sarcasm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...</td>\n",
       "      <td>M·ªåI NG∆Ø·ªúI NGHƒ® SAO V·ªÄ PH√ÅT BI·ªÇU C·ª¶A SHARK VI·ªÜT...</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>SHARK VI·ªÜT: ?NHI·ªÄU NG∆Ø·ªúI ·ªû VI·ªÜT NAM ƒêI L√ÄM CH·ªà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...</td>\n",
       "      <td>2 tay hai n√†ng ch·ª© vi·ªác g√¨ ph·∫£i l·ªá hai h√†ng</td>\n",
       "      <td>multi-sarcasm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10800</th>\n",
       "      <td>46ce5ad52085691fc81869c82e8222c0d737b34fedc2bd...</td>\n",
       "      <td>L·ªôn ƒë·∫ßu r·ªìi</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>L·ªòN ƒê·∫¶U R·ªíI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10801</th>\n",
       "      <td>f816f7152cca9c5899f818ce681cf0949c6964ea2fc5ae...</td>\n",
       "      <td>Ch√†o c√°c b·∫°n, m√¨nh l√† Goda Takeshi. Trong live...</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>0accae8d37f9edc90b5f0a2f5f3cca773f5d01b5124302...</td>\n",
       "      <td>Cre: H√πynh Qu·ªëc Huy</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>ƒê∆Ø·ª¢C BI·∫æT, CHI·∫æC M√ÅY C√ÅC NH√Ä KH·∫¢O ·∫¢NH N√ÄY ƒê√É C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10803</th>\n",
       "      <td>bf125e295f85c0946940b789b2ba10106b2a85b9e70d88...</td>\n",
       "      <td>Anh h√πng th·∫≠t s·ª±</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>T·ªö S·∫º D√ôNG C√ÇY V·ªöI M·ªòT B√öA N√ÄY ƒê·∫¨P N√ÅT TAY TH√î...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>a8bd707f12b5f47bbb42b501eb1ae896c22a474155ec0d...</td>\n",
       "      <td>Qu√° l√† b√¨nh th∆∞·ªùng üò§\\n- Butch3r\\n#interpool</td>\n",
       "      <td>not-sarcasm</td>\n",
       "      <td>Interpool Nh·ªØng k√™ khi ƒë·∫°t m√¥ng m∆° 200ksub Nic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10805 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  \\\n",
       "0      8ae451edcd8ebf697f8763ece249115813149c55733bf8...   \n",
       "1      35370ffd6c791d6f8c4ab3dd4363ed468fab41e4824ee9...   \n",
       "2      316fdd1477725b9fb1a55015ac06b68b92b50bd4303e08...   \n",
       "3      8a0f34e0e30e4e5cfb306933c1d25fa801a5da78646b59...   \n",
       "4      e517a5e95d1065886a7c815e82fe254381d4f9f4b244d4...   \n",
       "...                                                  ...   \n",
       "10800  46ce5ad52085691fc81869c82e8222c0d737b34fedc2bd...   \n",
       "10801  f816f7152cca9c5899f818ce681cf0949c6964ea2fc5ae...   \n",
       "10802  0accae8d37f9edc90b5f0a2f5f3cca773f5d01b5124302...   \n",
       "10803  bf125e295f85c0946940b789b2ba10106b2a85b9e70d88...   \n",
       "10804  a8bd707f12b5f47bbb42b501eb1ae896c22a474155ec0d...   \n",
       "\n",
       "                                                 caption          label  \\\n",
       "0                C√¥ ·∫•y tr√™n m·∫°ng vs c√¥ ·∫•y ngo√†i ƒë·ªùi =)))  multi-sarcasm   \n",
       "1        Ng∆∞·ªùi t√¢m linh giao ti·∫øp v·ªõi ng∆∞·ªùi th·ª±c t·∫ø :)))    not-sarcasm   \n",
       "2      H√¨nh nh∆∞ TrƒÉng h√¥m nay ƒë·∫πp qu√° m·ªçi ng∆∞·ªùi ·∫°! üòÉ ...  multi-sarcasm   \n",
       "3      M·ªåI NG∆Ø·ªúI NGHƒ® SAO V·ªÄ PH√ÅT BI·ªÇU C·ª¶A SHARK VI·ªÜT...    not-sarcasm   \n",
       "4            2 tay hai n√†ng ch·ª© vi·ªác g√¨ ph·∫£i l·ªá hai h√†ng  multi-sarcasm   \n",
       "...                                                  ...            ...   \n",
       "10800                                        L·ªôn ƒë·∫ßu r·ªìi    not-sarcasm   \n",
       "10801  Ch√†o c√°c b·∫°n, m√¨nh l√† Goda Takeshi. Trong live...    not-sarcasm   \n",
       "10802                                Cre: H√πynh Qu·ªëc Huy    not-sarcasm   \n",
       "10803                                   Anh h√πng th·∫≠t s·ª±    not-sarcasm   \n",
       "10804        Qu√° l√† b√¨nh th∆∞·ªùng üò§\\n- Butch3r\\n#interpool    not-sarcasm   \n",
       "\n",
       "                                              image_text  \n",
       "0                                                    NaN  \n",
       "1      CALZ Ch·ªën Sukinchana b√†n th·ªù ƒë·ªôt nhi√™n b·ªã ƒë·ªï r...  \n",
       "2                                                    NaN  \n",
       "3      SHARK VI·ªÜT: ?NHI·ªÄU NG∆Ø·ªúI ·ªû VI·ªÜT NAM ƒêI L√ÄM CH·ªà...  \n",
       "4                                                    NaN  \n",
       "...                                                  ...  \n",
       "10800                                        L·ªòN ƒê·∫¶U R·ªíI  \n",
       "10801                                                NaN  \n",
       "10802  ƒê∆Ø·ª¢C BI·∫æT, CHI·∫æC M√ÅY C√ÅC NH√Ä KH·∫¢O ·∫¢NH N√ÄY ƒê√É C...  \n",
       "10803  T·ªö S·∫º D√ôNG C√ÇY V·ªöI M·ªòT B√öA N√ÄY ƒê·∫¨P N√ÅT TAY TH√î...  \n",
       "10804  Interpool Nh·ªØng k√™ khi ƒë·∫°t m√¥ng m∆° 200ksub Nic...  \n",
       "\n",
       "[10805 rows x 4 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.merge(df_images[['image', 'Label']], on='image', how='left')\n",
    "df_train.rename(columns={'Label': 'image_text'}, inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObB9zB6qzi2t"
   },
   "source": [
    "## __CHU·∫®N  B·ªä D·ªÆ LI·ªÜU ƒê·ªÇ TRAIN__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9kD3mEKzi2t"
   },
   "source": [
    "### __D√ôNG CLIP__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __IMAGES__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rTFvlrbszi2t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nguyen_Thanh_Vinh\\anaconda3\\envs\\RP_Env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Nguyen_Thanh_Vinh\\anaconda3\\envs\\RP_Env\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh v√† processor t·ª´ Hugging Face\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "73owfgMazi2u"
   },
   "outputs": [],
   "source": [
    "def vector_image(data):\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    train_X = pd.DataFrame(columns=['image', 'image_vector', 'sarcasm'])\n",
    "    for idx, row in data.iterrows():\n",
    "\n",
    "        try:\n",
    "            image = folder + 'test-images\\\\' + row['image']\n",
    "\n",
    "            image = Image.open(image)\n",
    "\n",
    "            inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "            # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (embedding) t·ª´ h√¨nh ·∫£nh\n",
    "            with torch.no_grad():\n",
    "                image_features = model.get_image_features(**inputs)\n",
    "\n",
    "            # text = row['text']\n",
    "            # inputs_text = processor(text=text, return_tensors=\"pt\")\n",
    "\n",
    "            # # Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (embedding) t·ª´ vƒÉn b·∫£n\n",
    "            # with torch.no_grad():\n",
    "            #     text_features = model.get_text_features(**inputs_text)\n",
    "\n",
    "            new_row = {'image': row['image'], 'image_vector': image_features, 'sarcasm': row['label']}\n",
    "            train_X.loc[len(train_X)] = new_row\n",
    "        except Exception as e:\n",
    "            print(row['image'])\n",
    "\n",
    "        if int(idx) == len(data) - 1:\n",
    "            count += 1\n",
    "            file_name = f'image_private_{count}.csv'\n",
    "            train_X.to_csv(file_name, index=False)\n",
    "            print('Save {}'.format(count))\n",
    "            train_X = pd.DataFrame(columns=['image', 'image_vector', 'sarcasm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zo-cOSEMzi2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 1\n"
     ]
    }
   ],
   "source": [
    "vector_image(df_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __CAPTION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_text(data):\n",
    "    count = 0\n",
    "    train_X = pd.DataFrame(columns=['id', 'caption_features', 'sarcasm'])\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        try:\n",
    "            text = row['caption']\n",
    "            # M√£ h√≥a vƒÉn b·∫£n v√† l·∫•y s·ªë l∆∞·ª£ng token\n",
    "            inputs = processor(text=text, return_tensors=\"pt\", truncation=False)\n",
    "            token_ids = inputs['input_ids'][0]  # L·∫•y tensor ƒë·∫ßu ti√™n\n",
    "\n",
    "            # Ki·ªÉm tra s·ªë l∆∞·ª£ng token\n",
    "            if len(token_ids) > 77:\n",
    "                # Chia nh·ªè th√†nh c√°c ƒëo·∫°n kh√¥ng qu√° 76 token\n",
    "                chunks = [token_ids[i:i + 76] for i in range(0, len(token_ids), 76)]\n",
    "            else:\n",
    "                chunks = [token_ids]\n",
    "\n",
    "            text_features_list = []\n",
    "\n",
    "            # X·ª≠ l√Ω t·ª´ng ƒëo·∫°n\n",
    "            for chunk in chunks:\n",
    "                inputs_chunk = processor.tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "                inputs = processor(text=inputs_chunk, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=77)\n",
    "\n",
    "                # L·∫•y ƒë·∫∑c tr∆∞ng vƒÉn b·∫£n\n",
    "                with torch.no_grad():\n",
    "                    text_features = model.get_text_features(**inputs)\n",
    "                    text_features_list.append(text_features)\n",
    "\n",
    "            # K·∫øt h·ª£p c√°c ƒë·∫∑c tr∆∞ng\n",
    "            if text_features_list:\n",
    "                text_features_tensor = torch.stack(text_features_list)\n",
    "                combined_features = torch.mean(text_features_tensor, dim=0)\n",
    "\n",
    "                new_row = {'id': idx, 'caption_features': combined_features, 'sarcasm': row['label']}\n",
    "                train_X.loc[len(train_X)] = new_row\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "\n",
    "        if int(idx) == len(data) - 1:\n",
    "            count += 1\n",
    "            file_name = f'test_private_{count}.csv'\n",
    "            train_X.to_csv(file_name, index=False)\n",
    "            print(f'Save {count}')\n",
    "            train_X = pd.DataFrame(columns=['id', 'caption_features', 'sarcasm'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (271 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 1\n"
     ]
    }
   ],
   "source": [
    "vector_text(df_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __IMAGE_TEXT__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINVE</td>\n",
       "      <td>066d6021fdfeaf39f1dec523879e8fe4d35e877abcea44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wileup</td>\n",
       "      <td>555f4787d4df49e7be743b3d5b77c90755f0d6c351f36b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMANYMS Brizm LINVE</td>\n",
       "      <td>7b7cdea2cde1f3f93371259b587a03f2e8c0af682b4d51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brizm LINVE</td>\n",
       "      <td>80167e59d729cf3aaba5d2d3da40db6995cb8a6a8c4a88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m 12 GNOGASA ROUP FAN MUS·∫º TH·∫§Y TH·∫¨T L√Ä C·∫¢M GI...</td>\n",
       "      <td>59db087307031d60755af3a5c01a44ba55a04bfab21027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>Th·∫Øng Cu·ªôi 1 gi·ªù M·∫π b·∫£o hai ƒë·ª©a n√™n ƒëi t·∫≠p gym...</td>\n",
       "      <td>3c643826258f8aacc8a98d8e24956f909797010f1e80bd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>A/ KFC] T·ª™ ƒÇN L·∫§Y H√äN ƒêI CON, COMBO L·ªòC PH√öC V...</td>\n",
       "      <td>09f5adf3e555d3066eae0be356e5ce797c066706e7c808...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>B√âO [RA R·ªíI SU·ªêT NG√ÄY ƒÇN V·ªöI NG·ª¶, PH·∫¢I KI·ªÇM SO...</td>\n",
       "      <td>b11515c1aa521da4f6d0cd6464e5ea3e030662cdd43f7f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>24 09638222222 Mediavtv24eagmall.com 76% s·ªë ca...</td>\n",
       "      <td>8a83634808704a5c7493327893f793effd6e78cb037ac4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>HATTIEU CHANNETS em qua nh√† m·∫π ch·ªìng tr·ªï t√†i n...</td>\n",
       "      <td>20f81dd1d0329d6b7e5778304422a3621dae460a433ac2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1504 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Label  \\\n",
       "0                                                 LINVE   \n",
       "1                                                Wileup   \n",
       "2                                   AMANYMS Brizm LINVE   \n",
       "3                                           Brizm LINVE   \n",
       "4     m 12 GNOGASA ROUP FAN MUS·∫º TH·∫§Y TH·∫¨T L√Ä C·∫¢M GI...   \n",
       "...                                                 ...   \n",
       "1499  Th·∫Øng Cu·ªôi 1 gi·ªù M·∫π b·∫£o hai ƒë·ª©a n√™n ƒëi t·∫≠p gym...   \n",
       "1500  A/ KFC] T·ª™ ƒÇN L·∫§Y H√äN ƒêI CON, COMBO L·ªòC PH√öC V...   \n",
       "1501  B√âO [RA R·ªíI SU·ªêT NG√ÄY ƒÇN V·ªöI NG·ª¶, PH·∫¢I KI·ªÇM SO...   \n",
       "1502  24 09638222222 Mediavtv24eagmall.com 76% s·ªë ca...   \n",
       "1503  HATTIEU CHANNETS em qua nh√† m·∫π ch·ªìng tr·ªï t√†i n...   \n",
       "\n",
       "                                                  image  \n",
       "0     066d6021fdfeaf39f1dec523879e8fe4d35e877abcea44...  \n",
       "1     555f4787d4df49e7be743b3d5b77c90755f0d6c351f36b...  \n",
       "2     7b7cdea2cde1f3f93371259b587a03f2e8c0af682b4d51...  \n",
       "3     80167e59d729cf3aaba5d2d3da40db6995cb8a6a8c4a88...  \n",
       "4     59db087307031d60755af3a5c01a44ba55a04bfab21027...  \n",
       "...                                                 ...  \n",
       "1499  3c643826258f8aacc8a98d8e24956f909797010f1e80bd...  \n",
       "1500  09f5adf3e555d3066eae0be356e5ce797c066706e7c808...  \n",
       "1501  b11515c1aa521da4f6d0cd6464e5ea3e030662cdd43f7f...  \n",
       "1502  8a83634808704a5c7493327893f793effd6e78cb037ac4...  \n",
       "1503  20f81dd1d0329d6b7e5778304422a3621dae460a433ac2...  \n",
       "\n",
       "[1504 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(folder + 'private_text_in_image.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_text(data):\n",
    "    count = 0\n",
    "    train_X = pd.DataFrame(columns=['image', 'image_text'])\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        try:\n",
    "            text = row['Label']\n",
    "            # M√£ h√≥a vƒÉn b·∫£n v√† l·∫•y s·ªë l∆∞·ª£ng token\n",
    "            if pd.isna(text):  # Ki·ªÉm tra n·∫øu text l√† NaN\n",
    "                # G√°n vector to√†n s·ªë 0\n",
    "                zero_vector = torch.zeros(1, model.config.projection_dim)  # K√≠ch th∆∞·ªõc vector theo m√¥ h√¨nh\n",
    "                new_row = {'image': row['image'], 'image_text': zero_vector}\n",
    "                train_X.loc[len(train_X)] = new_row\n",
    "                continue  # B·ªè qua ph·∫ßn c√≤n l·∫°i v√† chuy·ªÉn sang h√†ng ti·∫øp theo\n",
    "            \n",
    "            inputs = processor(text=text, return_tensors=\"pt\", truncation=False)\n",
    "            token_ids = inputs['input_ids'][0]  # L·∫•y tensor ƒë·∫ßu ti√™n\n",
    "\n",
    "            # Ki·ªÉm tra s·ªë l∆∞·ª£ng token\n",
    "            if len(token_ids) > 77:\n",
    "                # Chia nh·ªè th√†nh c√°c ƒëo·∫°n kh√¥ng qu√° 76 token\n",
    "                chunks = [token_ids[i:i + 76] for i in range(0, len(token_ids), 76)]\n",
    "            else:\n",
    "                chunks = [token_ids]\n",
    "\n",
    "            text_features_list = []\n",
    "\n",
    "            # X·ª≠ l√Ω t·ª´ng ƒëo·∫°n\n",
    "            for chunk in chunks:\n",
    "                inputs_chunk = processor.tokenizer.decode(chunk, skip_special_tokens=True)\n",
    "                inputs = processor(text=inputs_chunk, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=77)\n",
    "\n",
    "                # L·∫•y ƒë·∫∑c tr∆∞ng vƒÉn b·∫£n\n",
    "                with torch.no_grad():\n",
    "                    text_features = model.get_text_features(**inputs)\n",
    "                    text_features_list.append(text_features)\n",
    "\n",
    "            # K·∫øt h·ª£p c√°c ƒë·∫∑c tr∆∞ng\n",
    "            if text_features_list:\n",
    "                text_features_tensor = torch.stack(text_features_list)\n",
    "                combined_features = torch.mean(text_features_tensor, dim=0)\n",
    "\n",
    "                new_row = {'image': row['image'], 'image_text': combined_features}\n",
    "                train_X.loc[len(train_X)] = new_row\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx}: {e}\")\n",
    "\n",
    "        if int(idx) == len(data) - 1:\n",
    "            count += 1\n",
    "            file_name = f'image_text_private_{count}.csv'\n",
    "            train_X.to_csv(file_name, index=False)\n",
    "            print(f'Save {count}')\n",
    "            train_X = pd.DataFrame(columns=['image', 'image_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save 1\n"
     ]
    }
   ],
   "source": [
    "vector_text(df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
